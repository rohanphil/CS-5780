{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Project 2: The Perceptron</h2>\n",
    "\n",
    "\n",
    "<!--announcements-->\n",
    "<blockquote>\n",
    "    <center>\n",
    "    <img src=\"perceptron.png\" width=\"200px\" />\n",
    "    </center>\n",
    "      <p><cite><center>\"What, we asked, wasn't the Perceptron capable of?\"<br>\n",
    "      Rival, The New Yorker, December 6, 1958 P. 44</center>\n",
    "      </cite></p>\n",
    "</blockquote>\n",
    "\n",
    "<h3>Introduction</h3>\n",
    "<!--AÃ°albrandr-->\n",
    "\n",
    "<p>In this project, you will implement a simple Perceptron classifier to classify digits (or anything else).</p>\n",
    "\n",
    "<p><strong>Project Notes:</strong> This project may be done in teams of up to 2. Each group should submit their own solutions. The due date is <strong>11:59 pm EST on March 2nd</strong>. Late submissions are accepted and the late due date is <strong>11:59 pm EST on March 4th</strong>. Submissions beyond the late due date will not be recorded.\n",
    "\n",
    "<strong>How to submit:</strong> You can submit your code using the <strong>Submit</strong> button above. This button will send any code below surrounded by <strong>#&lt;GRADED&gt;</strong><strong>#&lt;/GRADED&gt;</strong> tags below to the autograder, which will then run several tests over your code. By clicking on the <strong>Details</strong> dropdown next to the Submit button, you will be able to view your submission report once the autograder has completed running. This submission report contains a summary of the tests you have failed or passed, as well as a log of any errors generated by your code when we ran it.\n",
    "\n",
    "Note that this may take a while depending on how long your code takes to run! Once your code is submitted you may navigate away from the page as you desire -- the most recent submission report will always be available from the Details menu.\n",
    "\n",
    "<p><strong>Evaluation:</strong> Your code will be autograded for technical\n",
    "correctness. Please <em>do not</em> change the names of any provided functions or classes within the code, or you will wreak havoc on the autograder. However, the correctness of your implementation -- not the autograder's output -- will be the final judge of your score.  If necessary, we will review and grade assignments individually to ensure that you receive due credit for your work.\n",
    "\n",
    "<p><strong>Academic Dishonesty:</strong> We will be checking your code against other submissions in the class for logical redundancy. If you copy someone else's code and submit it with minor changes, we will know. These cheat detectors are quite hard to fool, so please don't try. We trust you all to submit your team's own work only; <em>please</em> don't let us down. If you do, we will pursue the strongest consequences available to us.\n",
    "\n",
    "<p><strong>Getting Help:</strong> You are not alone!  If you find yourself stuck  on something, contact the course staff for help.  Office hours, section, and the <a href=\"https://edstem.org/us/courses/19541/\">Ed Discussion</a> are there for your support; please use them.  We want these projects to be rewarding and instructional, not frustrating and demoralizing.  But, we don't know when or how to help unless you ask.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>Python initialization:</strong> Please run the following code to initialize your Python kernel. You should be running a version of Python 3.x. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running python 3.7.6\n"
     ]
    }
   ],
   "source": [
    "#<GRADED>\n",
    "import numpy as np\n",
    "from matplotlib import *\n",
    "#matplotlib.use('PDF')\n",
    "from pylab import *\n",
    "from collections import Counter\n",
    "#</GRADED>\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# add p02 folder\n",
    "sys.path.insert(0, './p02/')\n",
    "\n",
    "%matplotlib notebook\n",
    "print('You\\'re running python %s' % sys.version.split(' ')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> The Perceptron <b>(95 points)</b> </h3>\n",
    "\n",
    "<p>The perceptron is a basic linear classifier. The following questions will ask you to finish these functions in a pre-defined order. Unless specified otherwise, do not use loops.<br></p>\n",
    "\n",
    "<p>(a) Implement the process of updating the weight vector in the following function.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def perceptronUpdate(x,y,w):\n",
    "    \"\"\"\n",
    "    function w=perceptronUpdate(x,y,w);\n",
    "    \n",
    "    Implementation of Perceptron weights updating\n",
    "    Input:\n",
    "    x : input vector of d dimensions (d)\n",
    "    y : corresponding label (-1 or +1)\n",
    "    w : weight vector of d dimensions\n",
    "    \n",
    "    Output:\n",
    "    w : weight vector after updating (d)\n",
    "    \"\"\"\n",
    "    assert(y in {-1,1})\n",
    "    assert(len(w.shape)==1), \"At the update w must be a vector not a matrix (try w=w.flatten())\"\n",
    "    assert(len(x.shape)==1), \"At the update x must be a vector not a matrix (try x=x.flatten())\"\n",
    "    d, = x.shape\n",
    "    ## fill in code ...\n",
    "    w = w + y*x\n",
    "    ## ... until here\n",
    "    assert(len(w.shape)==1), \"After the update w must be a vector not a matrix (try w=w.flatten())\"\n",
    "    assert(w.shape[0] == d), \"w should be of shape 1 x d\"\n",
    "    return w.flatten()\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3cf7a12ef100>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# test the update code:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# random feature vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# random weight vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;31m# random label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mwnew\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mperceptronUpdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# do a perceptron update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# test the update code:\n",
    "x=np.random.rand(5) # random feature vector\n",
    "w=np.random.rand(5) # random weight vector\n",
    "y=-1 # random label\n",
    "wnew=perceptronUpdate(x,y,w.copy()) # do a perceptron update\n",
    "assert(norm(wnew-w+x)<1e-10), \"perceptronUpdate didn't pass the test : (\" # if correct, this should return 0\n",
    "print(\"Looks like you passed the update test : )\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(b) Implement function <b><code>perceptron</code></b>. This should contain a loop that calls \n",
    "<b><code>perceptronUpdate</code></b>\n",
    " until it converges or the maximum iteration count, 100, has been reached.\n",
    " Make sure you randomize the order of the training data on each iteration. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def perceptron(xs,ys,max_iter=100):\n",
    "    \"\"\"\n",
    "    function w=perceptron(xs,ys);\n",
    "    \n",
    "    Implementation of a Perceptron classifier\n",
    "    Input:\n",
    "    xs : n input vectors of d dimensions (nxd)\n",
    "    ys : n labels (-1 or +1)\n",
    "    \n",
    "    Output:\n",
    "    w : weight vector (1xd)\n",
    "    b : bias term\n",
    "    \"\"\"\n",
    "\n",
    "    assert(len(xs.shape)==2), \"The first input to Perceptron must be a _matrix_ of row input vectors.\"\n",
    "    assert(len(ys.shape)==1), \"The second input to Perceptron must be a _vector_ of n labels (try ys.flatten()).\"\n",
    "        \n",
    "    n, d = xs.shape     # so we have n input vectors, of d dimensions each\n",
    "    \n",
    "    ## fill in code ...\n",
    "    ## ... until here\n",
    "    assert(len(w.shape)==1), \"After the update w must be a vector not a matrix (try w=w.flatten())\"\n",
    "    assert(w.shape[0]==d), \"w should be of shape 1 x d\"\n",
    "    return (w,b)\n",
    "\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> You can use the following script to test your code and visualize your perceptron on linearly separable data in 2 dimensions. Your classifier should find a separating hyperplane on such data.   </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of input vectors\n",
    "N = 100\n",
    "\n",
    "# generate random (linarly separable) data\n",
    "xs = np.random.rand(N, 2)*10-5\n",
    "\n",
    "# defining random hyperplane\n",
    "w0 = np.random.rand(2)\n",
    "b0 = rand()*2-1\n",
    "\n",
    "# assigning labels +1, -1 labels depending on what side of the plane they lie on\n",
    "ys = np.sign(xs.dot(w0)+b0)\n",
    "\n",
    "# call perceptron to find w from data\n",
    "w,b = perceptron(xs.copy(),ys.copy())\n",
    "\n",
    "# test if all points are classified correctly\n",
    "assert (all(np.sign(ys*(xs.dot(w)+b))==1.0))  # yw'x should be +1.0 for every input\n",
    "print(\"Looks like you passed the Perceptron test! :o)\")\n",
    "\n",
    "# we can make a pretty visualizxation\n",
    "from helperfunctions import visboundary\n",
    "visboundary(w,b,xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onclick(event):\n",
    "    global w,b,ldata,ax,line,xydata\n",
    "\n",
    "    pos=np.array([[event.xdata],[event.ydata]])\n",
    "    if event.key == 'shift': # add positive point\n",
    "        color='or'\n",
    "        label=1\n",
    "    else: # add negative point\n",
    "        color='ob'\n",
    "        label=-1    \n",
    "    ax.plot(pos[0],pos[1],color)\n",
    "    ldata.append(label)\n",
    "    xydata=np.vstack((xydata,pos.T))\n",
    "    \n",
    "    # call Perceptron function\n",
    "    w,b=perceptron(xydata,np.array(ldata).flatten())\n",
    "\n",
    "    # draw decision boundary\n",
    "    q=-b/(w**2).sum() *w\n",
    "    intercept0 = -b/w[1]\n",
    "    intercept1 = -w[0]/w[1] - b/w[1]\n",
    "    if line==None:\n",
    "        line, = ax.plot([0, 1], [intercept0, intercept1], 'b--')\n",
    "        #line, = ax.plot([q[0]-w[1],q[0]+w[1]],[q[1]+w[0],q[1]-w[0]],'b--')\n",
    "    else:\n",
    "        line.set_data([0, 1], [intercept0, intercept1])\n",
    "        #line.set_data([q[0]-w[1],q[0]+w[1]],[q[1]+w[0],q[1]-w[0]])\n",
    "        \n",
    "\n",
    "\n",
    "xydata=rand(0,2)\n",
    "ldata=[]\n",
    "w=zeros(2)\n",
    "b=0\n",
    "line=None\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "title('Use shift-click to add negative points.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(c) \n",
    "\tImplement \n",
    "<b><code>classifyLinear</code></b>\n",
    " that applies the weight vector and bias to the input vector. (The bias is an optional parameter. If it is not passed in, assume it is zero.) Make sure that the predictions returned are either 1 or -1.</p> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def classifyLinear(xs,w,b=0):\n",
    "    \"\"\"\n",
    "    function preds=classifyLinear(xs,w,b)\n",
    "    \n",
    "    Make predictions with a linear classifier\n",
    "    Input:\n",
    "    xs : n input vectors of d dimensions (nxd) [could also be a single vector of d dimensions]\n",
    "    w : weight vector of dimensionality d\n",
    "    b : bias (scalar)\n",
    "    \n",
    "    Output:\n",
    "    preds: predictions (1xn)\n",
    "    \"\"\"    \n",
    "    w = w.flatten()    \n",
    "    n,_ = xs.shape\n",
    "    preds = np.zeros(n)\n",
    "    ## fill in code ...\n",
    "    ## ... until here\n",
    "    assert(preds.shape[0]==n), \"preds should be of size 1 x n\"\n",
    "    return preds\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test classifyLinear code:\n",
    "xs=rand(1000,2)-0.5 # draw random data \n",
    "w0=np.array([0.5,-0.3]) # define a random hyperplane \n",
    "b0=-0.1 # with bias -0.1\n",
    "ys=np.sign(xs.dot(w0)+b0) # assign labels according to this hyperplane (so you know it is linearly separable)\n",
    "assert (all(np.sign(ys*classifyLinear(xs,w0,b0))==1.0))  # the original hyperplane (w0,b0) should classify all correctly\n",
    "print(\"Looks like you passed the classifyLinear test! :o)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Competition <b>(5 points)</b></h3>\n",
    "\n",
    "<p>The competition for this assignment is to achieve the highest accuracy on the hidden test set (randomly sampled) using the perceptron algorithm you implemented above. You will have access to a training, and a validation set but not the actual test set.\n",
    "    \n",
    "You will receive full points on this section as long as you beat a baseline which we have implemented.\n",
    "\n",
    "<p>The competition for this assignment is split into three components you can modify:</p>\n",
    "\n",
    "<ol>\n",
    "<li><b>Feature Selection</b>:\n",
    "Modify the function <code>selectfeaturescomp</code>.\n",
    "This function takes in a list of file paths <code>paths</code>, a vector of training labels <code>labels</code> and\n",
    "a feature dimension <code>B</code> and outputs <code>B</code> tokens that are selected as features. This output is then passed into the feature extraction function described below.\n",
    "Notice this function runs on the training set only.\n",
    "We provide <code>selectfeaturesnaive</code> as an example.\n",
    "</li>\n",
    "<li><b>Feature Extraction</b>:\n",
    "Modify the function <code>extractfeaturescomp</code>.\n",
    "This function takes in a list of file paths <code>paths</code>,\n",
    "a feature dimension <code>B</code> and the output of your feature selection function <code>selected_features</code> and should output a feature matrix of dimension <code>n*B</code> (n examples as rows, with B columns each).\n",
    "The autograder will pass in a list of file paths pointing to files that contains an email,\n",
    "and set <code>B</code> = <code>feature_dimension</code>.\n",
    "This function is used to extract vectors from emails on both the training and test set.\n",
    "We provide <code>extractfeaturesnaive</code> as an example.\n",
    "</li>\n",
    "<li><b>Model Training</b>:\n",
    "Modify the function <code>trainspamfiltercomp</code>.\n",
    "This function takes in training data <code>xTr</code> and training labels <code>yTr</code> and\n",
    "should output a weight vector <code>w</code> for linear classification. <b>You must use the perceptron algorithm implemented above </b> although you are free to tweak the parameters such as the number of iterations.\n",
    "We provide an initial implementation of a random classifier.\n",
    "</li>\n",
    "</ol>\n",
    "\n",
    "<p>Your model will be trained on the following dataset (loaded by <code>loadspamdata</code>), but we will test its accuracy on a secret dataset of emails.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def tokenizer(path):\n",
    "    \"\"\"\n",
    "    Returns the tokens in one email file\n",
    "    You can use this tokenizer in your solution, or you can implement your own tokenizer\n",
    "    \n",
    "    Input:\n",
    "    path: string, path to the email file\n",
    "    Output:\n",
    "    list of tokens in the email\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as femail:\n",
    "        email = femail.read()\n",
    "        # breaks for non-ascii characters\n",
    "        tokens = email.split()\n",
    "    return tokens\n",
    "#</GRADED>\n",
    "\n",
    "def selectfeaturesnaive(paths, labels, B):\n",
    "    \"\"\"\n",
    "    A naive implementation of feature selection.\n",
    "    Returns the B most common words in the training emails.\n",
    "    This runs on the training set only.\n",
    "    \n",
    "    Input:\n",
    "    paths: list of length n, path to email files\n",
    "    labels: label vector of length n, +1 for spam and -1 for ham\n",
    "    B: int, the feature dimension\n",
    "    Output:\n",
    "    List of the B most common words, this will be used in the feature extracter\n",
    "    \"\"\"\n",
    "    # initialize a counter for all tokens\n",
    "    counter = Counter()\n",
    "    for i, path in enumerate(paths):\n",
    "        tokens = tokenizer(path)\n",
    "        counter.update(tokens)\n",
    "    # Get the most common words\n",
    "    most_common = [word for word, count in counter.most_common(B)]\n",
    "    return most_common\n",
    "\n",
    "def extractfeaturesnaive(paths, B, selected_feature):\n",
    "    \"\"\"\n",
    "    A naive implemenation of feature extraction.\n",
    "    Converts each email to a vector of length B, indicating the existence of each most common word\n",
    "    This runs on both the training and testing set.\n",
    "    \n",
    "    Input:\n",
    "    paths: list of length n, path to email files\n",
    "    B: int, the feature dimension\n",
    "    selected_feature: the output of selectfeaturesnaive()\n",
    "    Output:\n",
    "    n*B matrix, with each row vector corresponding to one email\n",
    "    \"\"\"\n",
    "    # initialize all-zeros feature vector\n",
    "    v = np.zeros((len(paths), B))\n",
    "    for (i, path) in enumerate(paths):\n",
    "        tokens = tokenizer(path) \n",
    "        for token in tokens:\n",
    "            if token in selected_feature:\n",
    "                v[i, selected_feature.index(token)] = 1\n",
    "            \n",
    "    return v\n",
    "\n",
    "def loadspamdata(selectfeatures, extractfeatures, B=50, path=\"../resource/lib/public/new_train_data/\"):\n",
    "    '''\n",
    "    INPUT:\n",
    "    selectfeatures  : function to select features\n",
    "    extractfeatures : function to extract features\n",
    "    B               : dimensionality of feature space\n",
    "    path            : the path of folder to be processed\n",
    "    \n",
    "    OUTPUT:\n",
    "    X, Y\n",
    "    '''\n",
    "    if path[-1] != '/':\n",
    "        path += '/'\n",
    "    \n",
    "    with open(path + 'index', 'r') as f:\n",
    "        allemails = [x for x in f.read().split('\\n') if ' ' in x]\n",
    "    \n",
    "    ys = np.zeros(len(allemails))\n",
    "    paths = []\n",
    "    for i, line in enumerate(allemails):\n",
    "        label, filename = line.split(' ')\n",
    "        # make labels +1 for \"spam\" and -1 for \"ham\"\n",
    "        ys[i] = (label == 'spam') * 2 - 1\n",
    "        paths.append(path+filename)\n",
    "    selected_feature = selectfeatures(paths, ys, B)\n",
    "    xs = extractfeatures(paths, B, selected_feature)\n",
    "    return xs, ys\n",
    "\n",
    "X,Y = loadspamdata(selectfeaturesnaive, extractfeaturesnaive)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is your training set. To do proper model selection and avoid overfitting, you should split it off into a validation set. Here's one implementation but feel free to <b> try other methods including k-fold cross validation </b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "\n",
    "def validation_split(X, Y):\n",
    "    # Split data into training and validation\n",
    "    n, d = X.shape\n",
    "    cutoff = int(np.ceil(0.8 * n))\n",
    "    # indices of training samples\n",
    "    xTr = X[:cutoff,:]\n",
    "    yTr = Y[:cutoff]\n",
    "    # indices of validation samples\n",
    "    xTv = X[cutoff:,:]\n",
    "    yTv = Y[cutoff:]\n",
    "\n",
    "    ## fill in code ...\n",
    "    ## ... until here\n",
    "    \n",
    "    return xTr, yTr, xTv, yTv\n",
    "\n",
    "#</GRADED>\n",
    "\n",
    "xTr, yTr, xTv, yTv = validation_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This should generate a training data set <code>xTr</code>, <code>yTr</code> and a validation set <code>xTv</code>, <code>yTv</code> for you. </p>\n",
    "\n",
    "<p>It is now time to implement your classifiers.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "## you may change the value of feature_dimension, but don't change the variable name\n",
    "feature_dimension = 50\n",
    "\n",
    "def selectfeaturescomp(paths, labels, B):\n",
    "    \"\"\"\n",
    "    Your implementation of feature selection.\n",
    "    This runs on the training set only.\n",
    "    You can copy from the naive implementation as a starting point.\n",
    "    \n",
    "    Input:\n",
    "    paths: list of length n, path to email files\n",
    "    labels: label vector of length n, +1 for spam and -1 for ham\n",
    "    B: int, the feature dimension\n",
    "    Output:\n",
    "    Anything you'd like\n",
    "    \"\"\"\n",
    "    ## fill in your code ...\n",
    "    return None\n",
    "\n",
    "def extractfeaturescomp(paths, B, selected_feature):\n",
    "    \"\"\"\n",
    "    Your implementation of feature extraction.\n",
    "    This runs on both the training and testing set.\n",
    "    You can copy from the naive implementation as a starting point.\n",
    "    \n",
    "    Input:\n",
    "    paths: list of length n, path to email files\n",
    "    B: int, the feature dimension\n",
    "    selected_feature: the output of your selectfeaturescomp()\n",
    "    Output:\n",
    "    n*B matrix, with each row vector corresponding to one email\n",
    "    \"\"\"\n",
    "    ## fill in code ...\n",
    "    return np.zeros((len(paths), B))\n",
    "    \n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def trainspamfiltercomp(xTr, yTr):\n",
    "    '''\n",
    "    INPUT:\n",
    "    xTr : nxd dimensional matrix (each row is an input vector)\n",
    "    yTr : d   dimensional vector (each entry is a label)\n",
    "    \n",
    "    OUTPUTS:\n",
    "    w : d dimensional vector for linear classification\n",
    "    b: bias term\n",
    "    '''\n",
    "    w = np.random.rand(np.shape(xTr)[1])\n",
    "    b = np.random.rand()\n",
    "    \n",
    "    ## fill in code ...\n",
    "    ## ... until here    \n",
    "    \n",
    "    return w,b\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Evaluate the performance on your validation set here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": [],
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
